{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Print a message to indicate the start of the process\nprint(\"Uploading packages...\")\n\n# Import necessary libraries\nimport os               # For operating system-related functions\nimport pandas as pd    # For data manipulation and analysis\nimport numpy as np     # For numerical operations\nimport tensorflow as tf # For deep learning with TensorFlow\nimport matplotlib.pyplot as plt # For plotting graphs and charts\nimport seaborn as sns  # For creating informative and attractive visualizations\n\n# Import specific modules and functions from TensorFlow and scikit-learn\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Print a message to indicate that the packages have been successfully loaded\nprint(\"Packages loaded.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training_validation_plots(history_model, start_epoch=0):\n    '''\n    Function to generate plots of accuracy and loss for training and validation sets.\n\n    Parameters:\n    - history_model: Historical training data (output from model training).\n    - start_epoch: The epoch number from which to generate the plots (default is 0).\n\n    Output:\n    - Two plots: The first one shows training and validation losses,\n                 and the second one shows training and validation accuracies.\n    '''\n\n    # Extract relevant historical training data\n    tr_acc = history_model.history['accuracy']        # Training accuracy\n    tr_loss = history_model.history['loss']           # Training loss\n    val_acc = history_model.history['val_accuracy']   # Validation accuracy\n    val_loss = history_model.history['val_loss']      # Validation loss\n    \n    # Find the index of the epoch with the lowest validation loss\n    index_loss = np.argmin(val_loss)\n    val_lowest = val_loss[index_loss]\n    \n    # Find the index of the epoch with the highest validation accuracy\n    index_acc = np.argmax(val_acc)\n    acc_highest = val_acc[index_acc]\n    \n    # Create a list of epoch numbers for the x-axis of the plots\n    Epochs = [i+1 for i in range(len(tr_acc))]\n    \n    # Labels to indicate the best epochs for loss and accuracy\n    loss_label = f'best epoch= {str(index_loss + 1)}'\n    acc_label = f'best epoch= {str(index_acc + 1)}'\n\n    # Plot training history\n    sns.set(font_scale=1.5)  \n    plt.figure(figsize= (20, 8), facecolor=\"w\")\n    plt.style.use('fivethirtyeight')\n\n    # Subplot 1: Training and Validation Loss\n    plt.subplot(1, 2, 1)\n    plt.plot(Epochs[start_epoch:], tr_loss[start_epoch:], 'r', label= 'Training loss')\n    plt.plot(Epochs[start_epoch:], val_loss[start_epoch:], 'g', label= 'Validation loss')\n    plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    # Subplot 2: Training and Validation Accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n    plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    # Ensure tight layout and display the plots\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(test_true_labels, test_predictions, class_names):\n    '''\n    Function to create and display a confusion matrix plot.\n\n    Parameters:\n    - test_true_labels: True class labels for the test data.\n    - test_predictions: Predicted class labels for the test data.\n    - class_names: List of class names for labeling the matrix.\n\n    Output:\n    - Displayed confusion matrix plot.\n    '''\n    \n    # Create a confusion matrix\n    confusion = confusion_matrix(test_true_labels, test_predictions)\n\n    # Create a figure for the confusion matrix plot\n    plt.figure(figsize=(5.7, 3.7), facecolor=\"w\")\n    \n    # Set the font scale for better readability\n    sns.set(font_scale=1.4)  \n    \n    # Create a heatmap of the confusion matrix\n    sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n                xticklabels=class_names, yticklabels=class_names)\n    \n    # Add labels for the x and y axes\n    plt.xlabel(\"Predicted\", labelpad=40)\n    plt.ylabel(\"True\", labelpad=40)\n    \n    # Add a title to the plot\n    plt.title(\"Colon Confusion Matrix\")\n    \n    # Display the plot\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the directory where the data is located\ndata_dir = \"/kaggle/input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set\"\n\n# Initialize empty lists to store file paths and labels\nfilepaths = []\nlabels = []\n\n# List all the subdirectories (folds) in the main data directory\nfolds = os.listdir(data_dir)\n\n# Iterate through each fold\nfor fold in folds:\n    foldpath = os.path.join(data_dir, fold)  # Create the full path to the fold\n    flist = os.listdir(foldpath)             # List all files in the fold\n\n    # Iterate through each file in the fold\n    for f in flist:\n        f_path = os.path.join(foldpath, f)    # Create the full path to the file\n        filelist = os.listdir(f_path)         # List all files in the subdirectory\n\n        # Iterate through each file in the subdirectory\n        for file in filelist:\n            fpath = os.path.join(f_path, file)  # Create the full path to the file\n            filepaths.append(fpath)            # Append the file path to the list\n\n            # Determine the label based on the subdirectory name (fold)\n            if f == \"colon_aca\":\n                labels.append(\"Colon Adenocarcinoma\")\n            elif f == \"colon_n\":\n                labels.append(\"Colon Benign Tissue\")\n            elif f == \"lung_aca\":\n                labels.append(\"Lung Adenocarcinoma\")\n            elif f == \"lung_n\":\n                labels.append(\"Lung Benign Tissue\")\n            elif f == \"lung_scc\":\n                labels.append(\"Lung Squamous Cell Carcinoma\")\n\n# Create two Pandas Series for file paths and labels\nFseries = pd.Series(filepaths, name=\"filepaths\")\nLseries = pd.Series(labels, name=\"labels\")\n\n# Concatenate the two Series into one DataFrame\ndf = pd.concat([Fseries, Lseries], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split colon and lung images into different data frames \ndf_colon = df[(df[\"labels\"] == \"Colon Benign Tissue\") |\n              (df[\"labels\"] == \"Colon Adenocarcinoma\")]\ndf_lung = df[(df[\"labels\"] == \"Lung Adenocarcinoma\") |\n             (df[\"labels\"] == \"Lung Benign Tissue\") |\n             (df[\"labels\"] == \"Lung Squamous Cell Carcinoma\")]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of lung images for each class\ndf_lung[\"labels\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of colon images for each class\ndf_colon[\"labels\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Colon","metadata":{}},{"cell_type":"code","source":"# Split colon images into training, validation, and test subsets\n\n# Extract labels for stratified splitting\nstrat_colon = df_colon[\"labels\"]\n\n# Split the data into training and temporary subsets with an 80-20 split ratio\ntrain_df_colon, tmp_df_colon = train_test_split(df_colon,  \n                                                train_size=0.8, \n                                                shuffle=True, \n                                                random_state=42, \n                                                stratify=strat_colon)\n\n# Extract labels for further stratified splitting\nstrat_colon = tmp_df_colon[\"labels\"]\n\n# Split the temporary subset into validation and test subsets with a 50-50 split ratio\nval_df_colon, test_df_colon = train_test_split(tmp_df_colon,  \n                                               train_size=0.5, \n                                               shuffle=True, \n                                               random_state=42, \n                                               stratify=strat_colon)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create generators for train, validation, and test colon data\n\n# Define batch size and image dimensions\nbatch_size = 128\nX = Y = 224\n\n# Create a generator for the training data from the DataFrame train_df_colon\ntrain_generator_colon = ImageDataGenerator().flow_from_dataframe(train_df_colon,\n                                    x_col= \"filepaths\",        # Column containing file paths\n                                    y_col= \"labels\",           # Column containing labels\n                                    class_mode = \"binary\",     # Classification mode\n                                    target_size = (X, Y),      # Target image size\n                                    color_mode=\"rgb\",          # Color mode (RGB)\n                                    batch_size = batch_size,    # Batch size\n                                    shuffle = True,             # Shuffle the data\n                                    seed = 42)                  # Random seed for reproducibility\n\n# Create a generator for the validation data from the DataFrame val_df_colon\nval_generator_colon = ImageDataGenerator().flow_from_dataframe(val_df_colon,\n                                      x_col= \"filepaths\",        # Column containing file paths\n                                      y_col= \"labels\",           # Column containing labels\n                                      class_mode = \"binary\",     # Classification mode\n                                      target_size = (X, Y),      # Target image size\n                                      color_mode=\"rgb\",          # Color mode (RGB)\n                                      batch_size = batch_size,    # Batch size\n                                      shuffle = True,             # Shuffle the data\n                                      seed = 42)                  # Random seed for reproducibility\n\n# Create a generator for the test data from the DataFrame test_df_colon\ntest_generator_colon = ImageDataGenerator().flow_from_dataframe(test_df_colon,\n                                      x_col= \"filepaths\",        # Column containing file paths\n                                      y_col= \"labels\",           # Column containing labels\n                                      class_mode = \"binary\",     # Classification mode\n                                      target_size = (X, Y),      # Target image size\n                                      color_mode=\"rgb\",          # Color mode (RGB)\n                                      batch_size = batch_size,    # Batch size\n                                      shuffle = False,            # Do not shuffle the data (for evaluation)\n                                      seed = 42)                  # Random seed for reproducibility","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get a dictionary mapping class names to their assigned labels\nclass_indices = train_generator_colon.class_indices\n\n# Print the dictionary, which shows the mapping of class names to labels\nprint(class_indices)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a list of class names for colon image classification\nclass_names_colon = [\"Colon Adenocarcinoma\", \"Colon Benign Tissue\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Take true labels from test data generator\ntest_true_labels_colon = test_generator_colon.classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Colon Model 1","metadata":{}},{"cell_type":"code","source":"# Create a model architecture for binary classification\nmodel_1_colon = keras.models.Sequential([\n    # Convolutional layers with max pooling\n    keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\", input_shape=(X, Y, 3)),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(512, 3, activation=\"relu\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    \n    # Flatten the output\n    keras.layers.Flatten(),\n    \n    # Fully connected layers with dropout for regularization\n    keras.layers.Dense(512, activation=\"relu\"),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(256, activation=\"relu\"),\n    keras.layers.Dropout(0.5),\n    \n    # Output layer for binary classification with sigmoid activation\n    keras.layers.Dense(1, activation=\"sigmoid\") # binary classification\n])\n\n# Compile the model with an optimizer, loss function, and evaluation metric\nmodel_1_colon.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001),\n                loss=\"binary_crossentropy\", # binary classification\n                metrics=[\"accuracy\"])\n\n# Display a summary of the model architecture\nmodel_1_colon.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nhistory_1_colon = model_1_colon.fit(train_generator_colon,  # Training data generator\n                                    epochs=30,                # Number of training epochs\n                                    validation_data=val_generator_colon,  # Validation data generator\n                                    steps_per_epoch=len(train_generator_colon),  # Number of steps per training epoch\n                                    validation_steps=len(val_generator_colon))  # Number of steps per validation epoch\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict on the test data using the trained model\ntest_predictions_model_1_colon = model_1_colon.predict(test_generator_colon,\n                                                       steps=len(test_generator_colon),\n                                                       verbose=1)\n\n# Threshold the predicted probabilities to get binary predictions (0 or 1)\ntest_predictions_model_1_colon = (test_predictions_model_1_colon > 0.5).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the training and validation history of model_1_colon\ntraining_validation_plots(history_1_colon)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the training and validation history of model_1_colon\ntraining_validation_plots(history_1_colon, start_epoch=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate a classification report using the true labels and model predictions\nclass_report = classification_report(test_true_labels_colon,\n                                     test_predictions_model_1_colon,\n                                     target_names=class_names_colon,\n                                     digits=4)\n\n# Print the classification report\nprint(\"Classification Report:\")\nprint(class_report)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the confusion matrix to visualize model performance\nplot_confusion_matrix(test_true_labels=test_generator_colon.classes,   # True class labels from the test generator\n                      test_predictions=test_predictions_model_1_colon, # Model's predicted class labels\n                      class_names=class_names_colon)                   # Names of the classes for labeling\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Colon Model 2","metadata":{}},{"cell_type":"code","source":"# Create a model architecture for binary classification (model_2_colon)\n\n# Define the model architecture using Sequential\nmodel_2_colon = keras.models.Sequential([\n    # Convolutional layers with max pooling\n    keras.layers.Conv2D(64, 3, activation=\"tanh\", padding=\"same\", input_shape=(X, Y, 3)),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(128, 3, activation=\"tanh\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(256, 3, activation=\"tanh\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(512, 3, activation=\"tanh\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(700, 3, activation=\"tanh\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    \n    # Flatten the output\n    keras.layers.Flatten(),\n    \n    # Fully connected layers with dropout for regularization\n    keras.layers.Dense(512, activation=\"relu\"),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(256, activation=\"relu\"),\n    keras.layers.Dropout(0.5),\n    \n    # Output layer for binary classification with sigmoid activation\n    keras.layers.Dense(1, activation=\"sigmoid\") # binary classification\n])\n\n# Compile the model with an optimizer, loss function, and evaluation metric\nmodel_2_colon.compile(optimizer=tf.keras.optimizers.legacy.SGD(momentum=0.9,\n                                                               learning_rate=0.001,\n                                                               decay=0.01),\n                      loss=\"binary_crossentropy\", # binary classification\n                      metrics=[\"accuracy\"])\n\n# Display a summary of the model architecture\nmodel_2_colon.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the second model (model_2_colon)\n\n# Fit the model to the training data\nhistory_2_colon = model_2_colon.fit(train_generator_colon,      \n                                    epochs=30,      # Number of training epochs\n                                    validation_data=val_generator_colon,  \n                                    steps_per_epoch=len(train_generator_colon),  #\n                                    validation_steps=len(val_generator_colon))  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict on test data\ntest_predictions_model_2_colon = model_2_colon.predict(test_generator_colon,\n                                                       steps=len(test_generator_colon),\n                                                       verbose=1)\ntest_predictions_model_2_colon = (test_predictions_model_2_colon > 0.5).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_validation_plots(history_2_colon)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_report = classification_report(test_true_labels_colon,\n                                     test_predictions_model_2_colon,\n                                     target_names=class_names_colon,\n                                     digits=4)\nprint(\"Classification Report:\")\nprint(class_report)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(test_true_labels_colon,\n                      test_predictions_model_2_colon,\n                      class_names_colon)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lung","metadata":{}},{"cell_type":"code","source":"# Split lung images into training, validation, and test subsets\n\n# Extract labels for stratified splitting\nstrat_lung = df_lung[\"labels\"]\n\n# Split the data into training and temporary subsets with an 80-20 split ratio\ntrain_df_lung, tmp_df_lung = train_test_split(df_lung,  \n                                              train_size=0.8, \n                                              shuffle=True, \n                                              random_state=42, \n                                              stratify=strat_lung)\n\n# Extract labels for further stratified splitting\nstrat_lung = tmp_df_lung[\"labels\"]\n\n# Split the temporary subset into validation and test subsets with a 50-50 split ratio\nval_df_lung, test_df_lung = train_test_split(tmp_df_lung,  \n                                             train_size=0.5, \n                                             shuffle=True, \n                                             random_state=42, \n                                             stratify=strat_lung)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define batch size and image dimensions\nbatch_size = 128\nX = Y = 224\n\n# Create a generator for the training data from the DataFrame train_df_lung\ntrain_generator_lung = ImageDataGenerator().flow_from_dataframe(train_df_lung,\n                                    x_col= \"filepaths\",        # Column containing file paths\n                                    y_col= \"labels\",           # Column containing labels\n                                    class_mode = \"categorical\", # Classification mode (one-hot encoded)\n                                    target_size = (X, Y),      # Target image size\n                                    color_mode=\"rgb\",          # Color mode (RGB)\n                                    batch_size = batch_size,    # Batch size\n                                    shuffle = True,             # Shuffle the data\n                                    seed = 42)                  # Random seed for reproducibility\n\n# Create a generator for the validation data from the DataFrame val_df_lung\nval_generator_lung = ImageDataGenerator().flow_from_dataframe(val_df_lung,\n                                      x_col= \"filepaths\",        # Column containing file paths\n                                      y_col= \"labels\",           # Column containing labels\n                                      class_mode = \"categorical\", # Classification mode (one-hot encoded)\n                                      target_size = (X, Y),      # Target image size\n                                      color_mode=\"rgb\",          # Color mode (RGB)\n                                      batch_size = batch_size,    # Batch size\n                                      shuffle = True,             # Shuffle the data\n                                      seed = 42)                  # Random seed for reproducibility\n\n# Create a generator for the test data from the DataFrame test_df_lung\ntest_generator_lung = ImageDataGenerator().flow_from_dataframe(test_df_lung,\n                                      x_col= \"filepaths\",        # Column containing file paths\n                                      y_col= \"labels\",           # Column containing labels\n                                      class_mode = \"categorical\", # Classification mode (one-hot encoded)\n                                      target_size = (X, Y),      # Target image size\n                                      color_mode=\"rgb\",          # Color mode (RGB)\n                                      batch_size = batch_size,    # Batch size\n                                      shuffle = False,            # Do not shuffle the data (for evaluation)\n                                      seed = 42)                  # Random seed for reproducibility\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get a dictionary mapping class names to their assigned labels\nclass_indices = train_generator_lung.class_indices\n\n# Print the dictionary, which shows the mapping of class names to labels\nprint(class_indices)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a list of class names for lung image classification\nclass_names_lung = [\"Lung Adenocarcinoma\",\n                    \"Lung Benign Tissue\",\n                    \"Lung Squamous Cell Carcinoma\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Take true labels from test data generator\ntest_true_labels_lung = test_generator_lung.classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lung Model 1","metadata":{}},{"cell_type":"code","source":"# Define the number of classes based on the class indices\nclass_number = len(list(train_generator_lung.class_indices.keys()))\n\nmodel_1_lung = keras.models.Sequential([\n    # Convolutional layers with max pooling\n    keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\", input_shape=(X, Y, 3)),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(512, 3, activation=\"relu\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    \n    # Flatten the output\n    keras.layers.Flatten(),\n    \n    # Fully connected layers with dropout for regularization\n    keras.layers.Dense(512, activation=\"relu\"),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(256, activation=\"relu\"),\n    keras.layers.Dropout(0.5),\n    # Multi-class classification using softmax activation\n    keras.layers.Dense(class_number, activation=\"softmax\")\n])\n\n# Compile model\nmodel_1_lung.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate= 0.001),\n                     loss=\"categorical_crossentropy\", # Categorical cross-entropy loss for multi-class\n                     metrics=[\"accuracy\"])\n\n# Show model summary\nmodel_1_lung.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model\nhistory_1_lung = model_1_lung.fit(train_generator_lung,\n                    epochs=30,\n                    validation_data=val_generator_lung,\n                    steps_per_epoch=len(train_generator_lung),\n                    validation_steps=len(val_generator_lung))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict class probabilities for the test data using the trained model\ntest_predictions_model_1_lung = model_1_lung.predict(test_generator_lung)\n\n# Extract the class labels (indices) with the highest predicted probabilities for each sample\ntest_predictions_model_1_lung = np.argmax(test_predictions_model_1_lung, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the training and validation history of model_1_lung\ntraining_validation_plots(history_1_lung)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_validation_plots(history_1_lung, start_epoch=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate a classification report using the true labels and model predictions\nclass_report = classification_report(test_true_labels_lung,\n                                     test_predictions_model_1_lung,\n                                     target_names=class_names_lung,\n                                     digits=4)\n\n# Print the classification report\nprint(\"Classification Report:\")\nprint(class_report)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(test_true_labels_lung,\n                      test_predictions_model_1_lung,\n                      class_names_lung)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lung Model 2","metadata":{}},{"cell_type":"code","source":"class_number = len(list(train_generator_lung.class_indices.keys()))\n\n# Create model architecture for multi-class classification\nmodel_2_lung = keras.models.Sequential([\n    keras.layers.Conv2D(64, 3, activation=\"tanh\", padding=\"same\", input_shape=(X, Y, 3)),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(128, 3, activation=\"tanh\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(256, 3, activation=\"tanh\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(512, 3, activation=\"tanh\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(700, 3, activation=\"tanh\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Flatten(),\n    keras.layers.Dense(512, activation=\"relu\"),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(256, activation=\"relu\"),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(class_number, activation=\"softmax\") # multi-class classification\n])\n\n# Compile model\nmodel_2_lung.compile(optimizer=tf.keras.optimizers.legacy.SGD(momentum=0.9,\n                                                              learning_rate=0.001,\n                                                              decay=0.01),\n                     loss=\"categorical_crossentropy\",\n                     metrics=[\"accuracy\"])\n\n# Show model summary\nmodel_2_lung.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model\nhistory_2_lung = model_2_lung.fit(train_generator_lung,\n                    epochs=30,\n                    validation_data=val_generator_lung,\n                    steps_per_epoch=len(train_generator_lung),\n                    validation_steps=len(val_generator_lung))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions_model_2_lung = model_2_lung.predict(test_generator_lung)\ntest_predictions_model_2_lung = np.argmax(test_predictions_model_2_lung, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_validation_plots(history_2_lung)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict on test data\ntest_predictions = model_2_lung.predict(test_generator_lung,\n                                        steps=len(test_generator_lung), \n                                        verbose=1)\n\n# Take true labels from test data generator\ntest_true_labels = test_generator_lung.classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate a classification report using the true labels and model predictions\nclass_report = classification_report(test_true_labels_lung, \n                                     test_predictions_model_2_lung, \n                                     target_names=class_names_lung, \n                                     digits=4)\nprint(\"Classification Report:\")\nprint(class_report)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(test_true_labels_lung, \n                      test_predictions_model_2_lung, \n                      class_names_lung)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Experiments","metadata":{}},{"cell_type":"code","source":"# Create a model architecture for binary classification without dropout (model_1_colon_no_dropout)\n\n# Define the model architecture using Sequential\nmodel_1_colon_no_dropout = keras.models.Sequential([\n    keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\", input_shape=(X, Y, 3)),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(512, 3, activation=\"relu\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Flatten(),\n    keras.layers.Dense(512, activation=\"relu\"),\n    keras.layers.Dense(256, activation=\"relu\"),\n    keras.layers.Dense(1, activation=\"sigmoid\") # binary classification\n])\n\n# Compile the model with an optimizer, loss function, and evaluation metric\nmodel_1_colon_no_dropout.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001),\n                                 loss=\"binary_crossentropy\", # Binary cross-entropy loss\n                                 metrics=[\"accuracy\"])\n\n# Display a summary of the model architecture\nmodel_1_colon_no_dropout.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model\nhistory_1_colon_no_dropout = model_1_colon_no_dropout.fit(train_generator_colon,\n                    epochs=30,\n                    validation_data=val_generator_colon,\n                    steps_per_epoch=len(train_generator_colon),\n                    validation_steps=len(val_generator_colon))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_validation_plots(history_1_colon_no_dropout)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_validation_plots(history_1_colon_no_dropout, start_epoch=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a model architecture for binary classification with \"tanh\" activation (model_1_colon_tanh)\n\n# Define the model architecture using Sequential\nmodel_1_colon_tanh = keras.models.Sequential([\n    keras.layers.Conv2D(64, 3, activation=\"tanh\", padding=\"same\", input_shape=(X, Y, 3)),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(128, 3, activation=\"tanh\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(256, 3, activation=\"tanh\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(512, 3, activation=\"tanh\", padding=\"same\"),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Flatten(),\n    keras.layers.Dense(512, activation=\"relu\"),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(256, activation=\"relu\"),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(1, activation=\"sigmoid\") # binary classification\n])\n\n# Compile the model with an optimizer, loss function, and evaluation metric\nmodel_1_colon_tanh.compile(optimizer=tf.keras.optimizers.legacy.SGD(momentum=0.9,\n                                                                   learning_rate=0.001,\n                                                                   decay=0.01),\n                           loss=\"binary_crossentropy\", # Binary cross-entropy loss\n                           metrics=[\"accuracy\"])\n\n# Display a summary of the model architecture\nmodel_1_colon_tanh.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model\nhistory_1_colon_tanh = model_1_colon_tanh.fit(train_generator_colon,\n                    epochs=30,\n                    validation_data=val_generator_colon,\n                    steps_per_epoch=len(train_generator_colon),\n                    validation_steps=len(val_generator_colon))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_validation_plots(history_1_colon_tanh)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict on test data\ntest_predictions_model_1_colon_tanh = model_1_colon_tanh.predict(test_generator_colon, steps=len(test_generator_colon), verbose=1)\ntest_predictions_model_1_colon_tanh = (test_predictions_model_1_colon_tanh > 0.5).astype(int)  # binary classification threshold","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate a classification report using the true labels and model predictions\nclass_report = classification_report(test_true_labels_colon,\n                                     test_predictions_model_1_colon_tanh,\n                                     target_names=class_names_colon,\n                                     digits=4)\n\n# Print the classification report\nprint(\"Classification Report:\")\nprint(class_report)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(test_true_labels_colon,\n                      test_predictions_model_1_colon_tanh,\n                      class_names_colon)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}